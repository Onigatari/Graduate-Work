{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3bd3b4-219b-4c3b-a7ee-61d253092206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re, os, time, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import LSTM, GRU, Input, Dense, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d99dca-d5f9-47c8-bb27-2cd56b9b6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2628a3b-41a1-4f5a-ae0b-f0b86b334101",
   "metadata": {},
   "source": [
    "# 1. Подготовка даных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ddd6f5b-f224-40b9-bf48-917cb4828503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w, punctuation=False, toSeq=False):\n",
    "    \"\"\"\n",
    "        Функция для предобработки \n",
    "    \"\"\"\n",
    "    \n",
    "    # Уменьшаем регистр и убираем лишние пробелы\n",
    "    w = w.lower().strip()\n",
    "    \n",
    "    # Замена всех символов 'æ' на однотипный\n",
    "    w = re.sub(r\"ӕ\", r\"æ\", w)\n",
    "    \n",
    "    # Удаление апострофом\n",
    "    w = re.sub(\"'\", '', w)\n",
    "    \n",
    "    if punctuation:\n",
    "        # Делаем между словом и знаком пунктуации отступ 'слово! -> слово !'\n",
    "        w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "        w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    else:\n",
    "        # Удаляет все знаки пунктуации\n",
    "        w = re.sub(r\"[^\\w\\s]\", r\"\", w)\n",
    "    \n",
    "    # Выкидываем все остальные символы из рассмотрения \n",
    "    w = re.sub(r\"[^a-яА-Яa-zA-Z?.!,æё]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    \n",
    "    # Добавляем токены для начала и конца предложения\n",
    "    if toSeq:\n",
    "        w = f'<sos> {w} <eos>'\n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06889a21-0434-4753-883e-bf24d25b3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    \"\"\"\n",
    "        Функция, которая создаёт датасет\n",
    "    \"\"\"    \n",
    "    new_path = f'Date/{path}'\n",
    "    with open(new_path, encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    uncleaned_data_list = data.split('\\n')\n",
    "    \n",
    "    source_word = []\n",
    "    target_word = []\n",
    "    for word in uncleaned_data_list:\n",
    "        source_word.append(preprocess_sentence(word.split('\\t')[0], punctuation=False, toSeq=False))\n",
    "        target_word.append(preprocess_sentence(word.split('\\t')[1], punctuation=False, toSeq=True))\n",
    "        \n",
    "    language_data = pd.DataFrame(columns=['Source','Target'])\n",
    "    language_data['Source'] = source_word\n",
    "    language_data['Target'] = target_word\n",
    "    \n",
    "    return language_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a3d01f-6287-43ee-8672-526b327e7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_(text_data):\n",
    "    '''\n",
    "        Токенайзер\n",
    "    '''\n",
    "    \n",
    "    tokenizer = Tokenizer(filters='\"#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(text_data)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec8401d9-c9c7-402a-a4f5-4b363fe5464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(data):\n",
    "    max_length_ = max([len(x.split(' ')) for x in data])\n",
    "    return max_length_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298ea3a1-6e0b-4994-b6be-3e235160b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preparing_data(input_seq, output_seq):\n",
    "    tokenizer_input, tokenizer_output = tokenizer_(input_seq), tokenizer_(output_seq)\n",
    "    input_max_length, output_max_length = len(tokenizer_input.word_index) + 1, len(tokenizer_output.word_index) + 1\n",
    "    \n",
    "    return tokenizer_input, tokenizer_output, input_max_length, output_max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9138a1e2-7510-4933-b3f1-59d31d2efd0b",
   "metadata": {},
   "source": [
    "# 2. Построение модели Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86b68f6f-6c03-4d2a-8828-b99c366888d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "        Энкодер \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size_input, HIDDEN_DIM):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.inputs = Input(shape=(None,), name=\"encoder_inputs\")\n",
    "        self.embedding = Embedding(vocab_size_input, HIDDEN_DIM, mask_zero=True, name=\"encoder_embedding\")(self.inputs)\n",
    "        \n",
    "        encoder = GRU(HIDDEN_DIM, return_state=True, name=\"encoder_gru\")\n",
    "        self.outputs, state_h = encoder(self.embedding)\n",
    "        self.states = [state_h]\n",
    "        \n",
    "def getEncoder(model_loaded):\n",
    "    encoder_inputs_inf = model_loaded.input[0]\n",
    "    encoder_outputs_inf, inf_state_h = model_loaded.layers[4].output\n",
    "    encoder_inf_states = [inf_state_h]\n",
    "\n",
    "    return Model(encoder_inputs_inf,encoder_inf_states, name='Encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "454a1f31-5c8f-4274-9b7e-b6a712e855a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "        Декодер \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size_output, HIDDEN_DIM, encoder_states):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.inputs = Input(shape=(None,), name=\"decoder_inputs\")\n",
    "        self.embedding = Embedding(vocab_size_output, HIDDEN_DIM, mask_zero=True, name=\"decoder_embedding\")(self.inputs)\n",
    "        \n",
    "        decoder = GRU(HIDDEN_DIM, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "        self.outputs, _ = decoder(self.embedding, initial_state=encoder_states)\n",
    "        self.dense = Dense(vocab_size_output, activation='softmax', name=\"dense_gru\")\n",
    "        self.outputs = self.dense(self.outputs)\n",
    "        \n",
    "def getDecoder(model_loaded):\n",
    "    decoder_state_h_input = Input(shape=(HIDDEN_DIM,))\n",
    "    decoder_state_input = [decoder_state_h_input]\n",
    "\n",
    "    decoder_input_inf = model_loaded.input[1]\n",
    "    decoder_emb_inf = model_loaded.layers[3](decoder_input_inf)\n",
    "    decoder_gru_inf = model_loaded.layers[5]\n",
    "    decoder_output_inf, decoder_state_h_inf = decoder_gru_inf(decoder_emb_inf, initial_state=decoder_state_input)\n",
    "    decoder_state_inf = [decoder_state_h_inf]\n",
    "    dense_inf = model_loaded.layers[6]\n",
    "    decoder_output_final = dense_inf(decoder_output_inf)\n",
    "\n",
    "    return Model([decoder_input_inf]+decoder_state_input,[decoder_output_final]+decoder_state_inf, name='Decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81ad8a6a-e1dc-48de-b446-c2d7ff443ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batch(X, Y, batch_size):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_data_input = np.zeros((batch_size,max_lenght_source),dtype='float32') #metrix of batch_size*max_length_english\n",
    "            decoder_data_input = np.zeros((batch_size,max_lenght_target),dtype='float32') #metrix of batch_size*max_length_marathi\n",
    "            decoder_target_input = np.zeros((batch_size,max_lenght_target,vocab_size_target),dtype='float32') # 3d array one hot encoder decoder target data\n",
    "            for i, (input_text,target_text) in enumerate(zip(X[j:j+batch_size],Y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_data_input[i,t] = tokenizer_input.word_index[word] # Here we are storing the encoder \n",
    "                                                                         #seq in row here padding is done automaticaly as \n",
    "                                                                         #we have defined col as max_lenght\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    decoder_data_input[i,t] = tokenizer_output.word_index[word] # same for the decoder sequence\n",
    "                    if t>0:\n",
    "                        decoder_target_input[i,t-1,tokenizer_output.word_index[word]] = 1 #target is one timestep ahead of decoder input because it does not have 'start tag'\n",
    "            yield ([encoder_data_input,decoder_data_input],decoder_target_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a70c8d-84ee-44a6-ba55-6a17657e615d",
   "metadata": {},
   "source": [
    "# 3. Входные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f10c3abb-6cec-444f-b8fc-dd3b5c769a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 50\n",
    "batch_size = 6\n",
    "epochs = 20\n",
    "\n",
    "start_target = \"<sos>\"\n",
    "end_target = \"<eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e15cd9ae-e669-4474-9ea3-86744e9fb55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'rus-oss.txt'\n",
    "data = load_dataset(path)\n",
    "input_seq, output_seq = data['Source'].values, data['Target'].values\n",
    "tokenizer_input, tokenizer_output, vocab_size_source, vocab_size_target = get_preparing_data(input_seq, output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d268c4ac-2e11-40ab-bb2a-7e59897bc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path[:-4]}-tokenizer_input.pkl','wb') as f:\n",
    "    pkl.dump(tokenizer_input, f)\n",
    "\n",
    "with open(f'{path[:-4]}-tokenizer_output.pkl','wb') as f:\n",
    "    pkl.dump(tokenizer_output, f)\n",
    "\n",
    "pkl.dump(tokenizer_input, open(f'{path[:-4]}-tokenizer_input.pkl', 'wb'))\n",
    "pkl.dump(tokenizer_output, open(f'{path[:-4]}-tokenizer_output.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bc0848b-e173-4914-84c0-aef68b3845cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_seq, output_seq, test_size = 0.1)\n",
    "train_samples = len(X_train)\n",
    "test_samples = len(X_test)\n",
    "\n",
    "max_lenght_source = max_length(X_train)\n",
    "max_lenght_target = max_length(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8fb90c3-e972-4fa3-94ca-0b3c1067b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size_source, HIDDEN_DIM)\n",
    "decoder = Decoder(vocab_size_target, HIDDEN_DIM, encoder.states)\n",
    "\n",
    "model = Model([encoder.inputs, decoder.inputs], decoder.outputs, name=\"GRU-Translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c28ea3a-7a69-4e5b-a24a-a6c4145f6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = [\n",
    "    'categorical_crossentropy',\n",
    "    'binary_crossentropy',\n",
    "]\n",
    "\n",
    "now_loss_function = loss_function[0]\n",
    "model.compile(loss=now_loss_function, optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7de0242d-524b-4dc9-a2a6-aec17d24ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GRU-Translation\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, None, 50)     47250       ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 50)     46100       ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " encoder_gru (GRU)              [(None, 50),         15300       ['encoder_embedding[0][0]']      \n",
      "                                 (None, 50)]                                                      \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)              [(None, None, 50),   15300       ['decoder_embedding[0][0]',      \n",
      "                                 (None, 50)]                      'encoder_gru[0][1]']            \n",
      "                                                                                                  \n",
      " dense_gru (Dense)              (None, None, 922)    47022       ['decoder_gru[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 170,972\n",
      "Trainable params: 170,972\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6409fe07-d9e8-440f-a5bb-ce9ed3d5d4d7",
   "metadata": {},
   "source": [
    "# 4. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2760af39-9923-4671-8de5-012a2db00f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ONIGAT~1\\AppData\\Local\\Temp/ipykernel_43100/1321299230.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = Batch(X_train, y_train, batch_size = batch_size), steps_per_epoch = train_samples//batch_size, epochs=epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 7s 16ms/step - loss: 1.3294 - accuracy: 0.1530\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.2033 - accuracy: 0.1563\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.1844 - accuracy: 0.1564\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.1580 - accuracy: 0.1570\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.1297 - accuracy: 0.1654\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0993 - accuracy: 0.1684\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0702 - accuracy: 0.1697\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0580 - accuracy: 0.1699\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0387 - accuracy: 0.1722\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0321 - accuracy: 0.1723\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0101 - accuracy: 0.1729\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9957 - accuracy: 0.1757\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9927 - accuracy: 0.1762\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9838 - accuracy: 0.1783\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9709 - accuracy: 0.1807\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9611 - accuracy: 0.1824\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9585 - accuracy: 0.1839\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9476 - accuracy: 0.1866\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9470 - accuracy: 0.1855\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9365 - accuracy: 0.1886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22089176970>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%capture\n",
    "model.fit_generator(generator = Batch(X_train, y_train, batch_size = batch_size), steps_per_epoch = train_samples//batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f6a63-4868-4380-a9ec-3ea3069b8192",
   "metadata": {},
   "source": [
    "# 5. Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ebbda12-686d-47de-af07-63661bd10b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисовка схемы модели\n",
    "# plot_model(model, to_file=f'{dir}-{epochs}-train_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7db8682d-539a-4ace-9c95-3f414ee4fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save_JSON():\n",
    "    model_json = model.to_json()\n",
    "    \n",
    "    with open(f'GRU-[{path[:-4]}]-[Epochs={epochs}]-[LossFunction={now_loss_function}].json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    model.save_weights(f'GRU-[{path[:-4]}]-[Epochs={epochs}]-[LossFunction={now_loss_function}]-[weight].h5')\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a270dfdd-590f-46f9-88ac-331d15f8b34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_save_JSON()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48a794-6ae1-4ac4-bf9a-c57c1fa1918e",
   "metadata": {},
   "source": [
    "# 6. Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7155f866-a36c-4996-a56b-ee5682ae6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load_JSON():\n",
    "    json_file = open(f'GRU-[{path[:-4]}]-[Epochs={epochs}]-[LossFunction={now_loss_function}].json')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model_loaded = model_from_json(loaded_model_json)\n",
    "\n",
    "    model_loaded.load_weights(f'GRU-[{path[:-4]}]-[Epochs={epochs}]-[LossFunction={now_loss_function}]-[weight].h5')\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    return model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd55a3e8-a44f-4df8-b659-eb8d10788911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "model_loaded = model_load_JSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dbc917e-9bdb-4b2d-993d-209fc0eb5a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GRU-Translation\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, None, 50)     47250       ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 50)     46100       ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " encoder_gru (GRU)              [(None, 50),         15300       ['encoder_embedding[0][0]']      \n",
      "                                 (None, 50)]                                                      \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)              [(None, None, 50),   15300       ['decoder_embedding[0][0]',      \n",
      "                                 (None, 50)]                      'encoder_gru[0][1]']            \n",
      "                                                                                                  \n",
      " dense_gru (Dense)              (None, None, 922)    47022       ['decoder_gru[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 170,972\n",
      "Trainable params: 170,972\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba7c15b6-9095-453e-abb7-465a7504273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = getEncoder(model_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28f3ab23-a88c-47ab-8791-53785ae80f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = getDecoder(model_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d118094-3de5-4929-8071-403404efc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path[:-4]}-tokenizer_input.pkl','rb') as f:\n",
    "    tokenizer_input = pkl.load(f)\n",
    "with open(f'{path[:-4]}-tokenizer_output.pkl','rb') as f:\n",
    "    tokenizer_output = pkl.load(f)\n",
    "\n",
    "reverse_word_map_input = dict(map(reversed, tokenizer_input.word_index.items()))\n",
    "reverse_word_map_target = dict(map(reversed, tokenizer_output.word_index.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0530156f-4eb4-4639-9188-6e3a5f2868e5",
   "metadata": {},
   "source": [
    "# 7. Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eed2e084-c10e-44ae-a60d-df85654842f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_inputs (InputLayer)  [(None, None)]           0         \n",
      "                                                                 \n",
      " encoder_embedding (Embeddin  (None, None, 50)         47250     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " encoder_gru (GRU)           [(None, 50),              15300     \n",
      "                              (None, 50)]                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,550\n",
      "Trainable params: 62,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da6b1022-59f6-440b-a7a1-b6b19cb1e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Decoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 50)     46100       ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)              [(None, None, 50),   15300       ['decoder_embedding[1][0]',      \n",
      "                                 (None, 50)]                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_gru (Dense)              (None, None, 922)    47022       ['decoder_gru[1][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,422\n",
      "Trainable params: 108,422\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2c2f350-557d-4264-bc12-0f1d28d0f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(input_seq):\n",
    "    state_values_encoder = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = tokenizer_output.word_index[start_target]\n",
    "    stop_condition = False\n",
    "    decoder_sentance = ''\n",
    "    \n",
    "    print([target_seq] + state_values_encoder)\n",
    "    print( decoder_model.predict([target_seq] + state_values_encoder))\n",
    "    while not stop_condition:\n",
    "        sample_word, decoder_h = decoder_model.predict([target_seq] + state_values_encoder)\n",
    "        sample_word_index = np.argmax(sample_word[0,-1,:])\n",
    "        decoder_word = reverse_word_map_target[sample_word_index]\n",
    "        decoder_sentance += ' ' + decoder_word\n",
    "        if (decoder_word == end_target or \n",
    "            len(decoder_sentance) > 70):\n",
    "            stop_condition = True\n",
    "        target_seq[0, 0] = sample_word_index\n",
    "        state_values_encoder = [decoder_h]\n",
    "    return decoder_sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef51dc10-c109-429e-9bfa-34ca38f348f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.97279694 0.91261477 1.32319808 1.03823457 1.02584164 1.17029333\n",
      "   1.23843992 0.76908514 0.76150651 0.79735586 1.13605289 0.91015819\n",
      "   1.42006937 0.84848908 1.01905345 1.16627207 1.1340186  0.94678755\n",
      "   0.69204801 1.10904676 1.32606852 1.22133896 1.1362998  0.44371474\n",
      "   0.57982853 0.60379171 1.04445478 0.49940991 0.84193429 0.61265934\n",
      "   1.10971969 1.50798321 0.86740947 1.30370775 1.2688795  0.76367854\n",
      "   1.10739896 0.89647955 1.09840928 1.39756811 0.78056222 0.91183472\n",
      "   0.92390061 1.51099956 1.09970696 0.94902347 0.69569978 1.19216922\n",
      "   1.07049995 1.19394989]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"Decoder\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 50) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ONIGAT~1\\AppData\\Local\\Temp/ipykernel_43100/2499975244.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msentance\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpad_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpredicted_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test sentance: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentance: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ONIGAT~1\\AppData\\Local\\Temp/ipykernel_43100/3581257090.py\u001b[0m in \u001b[0;36mdecode_seq\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstate_values_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstate_values_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0msample_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstate_values_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programms\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programms\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"Decoder\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 50) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sentance = X_test[i]\n",
    "    original_target = y_test[i]\n",
    "    input_seq = tokenizer_input.texts_to_sequences([sentance])\n",
    "    pad_sequence = pad_sequences(input_seq, maxlen= 30, padding='post')\n",
    "    predicted_target = decode_seq(pad_sequence)\n",
    "    print(\"Test sentance: \",i+1)\n",
    "    print(\"sentance: \",sentance)\n",
    "    print(\"origianl translate:\",original_target[5:-5])\n",
    "    print(\"predicted Translate:\",predicted_target[:-5])\n",
    "    print(\"==\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91079afd-85f2-44cf-98e6-1b57e5734825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
