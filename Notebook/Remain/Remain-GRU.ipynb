{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3bd3b4-219b-4c3b-a7ee-61d253092206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, GRU, Input, Dense,Embedding\n",
    "from keras.models import Model,load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import model_from_json\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4dd2f02-e395-49ef-83a5-561264659141",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'rus-oss.txt'\n",
    "cur_path = os.path.abspath('')\n",
    "new_path = os.path.relpath(f'../Date/{dir}', cur_path)\n",
    "with open(new_path, encoding='utf-8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8594834f-8c22-42f2-9c9d-824682476705",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncleaned_data_list = data.split('\\n')\n",
    "uncleaned_data_list = uncleaned_data_list[:38695]\n",
    "\n",
    "source_word = []\n",
    "target_word = []\n",
    "start_target = \"sos\"\n",
    "end_target = \"eos\"\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "WORDS = 1000\n",
    "LENGTH = 100\n",
    "DEPTH = 32\n",
    "\n",
    "batch_size = 6\n",
    "epochs = 160\n",
    "\n",
    "for word in uncleaned_data_list:\n",
    "    source_word.append(word.split('\\t')[0])\n",
    "    target_word.append(word.split('\\t')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f26833-35c5-4c74-be15-a6aeee953077",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_data = pd.DataFrame(columns=['Source','Target'])\n",
    "language_data['Source'] = source_word\n",
    "language_data['Target'] = target_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1b8388-5baf-46d9-82e5-f82e11c68096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to csv\n",
    "language_data.to_csv(f'{dir}-language_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61839196-3044-4a75-9c9d-d31d92c56e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from csv\n",
    "language_data = pd.read_csv(f'{dir}-language_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74166bf2-1b9e-4c76-97cb-dcc10a6a832d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Чего ты смеёшься?</td>\n",
       "      <td>Цæуыл худыс?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Этот нож очень острый.</td>\n",
       "      <td>Ацы кард тынг цыргъ у.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>У кошки девять жизней.</td>\n",
       "      <td>Гæдыйæн фараст царды ис.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Сегодня облачно.</td>\n",
       "      <td>Абон у асæст.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Он был вождём своего племени 35 лет.</td>\n",
       "      <td>Уый йæ знæмы раздзог уыдис 35 азы дæргъы.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Source  \\\n",
       "0                     Чего ты смеёшься?   \n",
       "1                Этот нож очень острый.   \n",
       "2                У кошки девять жизней.   \n",
       "3                      Сегодня облачно.   \n",
       "4  Он был вождём своего племени 35 лет.   \n",
       "\n",
       "                                      Target  \n",
       "0                               Цæуыл худыс?  \n",
       "1                     Ацы кард тынг цыргъ у.  \n",
       "2                   Гæдыйæн фараст царды ис.  \n",
       "3                              Абон у асæст.  \n",
       "4  Уый йæ знæмы раздзог уыдис 35 азы дæргъы.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfaae43d-4b63-4b8e-9cfd-374bed9eaea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Делать</td>\n",
       "      <td>Кæнын</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Говорить</td>\n",
       "      <td>Дзурын</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Работать</td>\n",
       "      <td>Кусын</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Жить</td>\n",
       "      <td>Цæрын</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Кушать</td>\n",
       "      <td>Хæрын</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Source  Target\n",
       "465    Делать   Кæнын\n",
       "466  Говорить  Дзурын\n",
       "467  Работать   Кусын\n",
       "468      Жить   Цæрын\n",
       "469    Кушать   Хæрын"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d07c12e3-2ae9-4ff9-910d-157045ae2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_word = language_data['Source'].values\n",
    "target_word = language_data['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d4e6e5-6446-49c1-b5b3-2f06c0caf170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Чего ты смеёшься?', 'Цæуыл худыс?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_word[0], target_word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9becfba-23ea-4161-baf7-db337fff0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercasing the setences\n",
    "source_word_ = [x.lower() for x in source_word]\n",
    "target_word_ = [x.lower() for x in target_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a263f311-c1f2-4398-9cb7-25b657d87f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_word_ = [re.sub(\"'\",'',x) for x in source_word_]\n",
    "target_word_ = [re.sub(\"'\",'',x) for x in target_word_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "430f9bf7-974c-4c5c-9f08-20f196c87fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_word_ = [x.strip() for x in source_word_]\n",
    "target_word_ = [x.strip() for x in target_word_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969fe0cb-c166-451b-8c9f-db502220db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_word_ = [re.sub(r\"[^\\w\\s]\", r\"\", x) for x in source_word_]\n",
    "target_word_ = [re.sub(r\"[^\\w\\s]\", r\"\", x) for x in target_word_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "380ba5df-9087-41c0-ba3b-213fc39b72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_word_ = [re.sub(r\"\\d\", r\"\", x) for x in source_word_]\n",
    "target_word_ = [re.sub(r\"\\d\", r\"\", x) for x in target_word_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48241391-0b5f-4894-a016-3abfa7b7b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_word_ = [re.sub('\"', '', x) for x in source_word_]\n",
    "target_word_ = [re.sub('\"', '', x) for x in target_word_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "561876ed-d15b-4d74-a6f0-ac977aa15200",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_word_ = [re.sub(r\"ӕ\", r\"æ\", x) for x in source_word_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b11ab261-579e-4796-9270-b7412d744761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_word_ = [f'{start_target} {x} {end_target}' for x in source_word_]\n",
    "target_word_ = [f'{start_target} {x} {end_target}' for x in target_word_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31e666cc-a2c4-44fa-b2be-5fce7a707e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('чего ты смеёшься', 'sos цæуыл худыс eos')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_word_[0], target_word_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66aacda-d7c5-432e-b4ef-26894828d82b",
   "metadata": {},
   "source": [
    "# Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cd1a947-3809-44e3-9a95-f7beb88e9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = source_word_\n",
    "Y = target_word_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f162257-a1b4-4f95-8924-c0a8d8cfec23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 423, 47, 47)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1)\n",
    "len(X_train),len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "831ccdc4-2ac5-47a6-bdf8-03d08ecd2652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('чего ты смеёшься', 'sos цæуыл худыс eos')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a866d-44e2-47a3-8347-8f343cadafe6",
   "metadata": {},
   "source": [
    "## Data preparing for encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "979cfe58-63c5-4c4a-be81-23caf194cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for the word embedding\n",
    "def Max_length(data):\n",
    "    max_length_ = max([len(x.split(' ')) for x in data])\n",
    "    return max_length_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8a27121-00cd-48b0-93bb-d83113a79c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data\n",
    "max_lenght_source = Max_length(X_train)\n",
    "max_lenght_target = Max_length(y_train)\n",
    "\n",
    "#Test data\n",
    "max_lenght_source_test = Max_length(X_test)\n",
    "max_lenght_target_test = Max_length(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4af652ed-5759-4cce-8c21-1c54464057d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 21)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_lenght_target, max_lenght_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "830d97c3-5032-4a1d-9cc8-4a5e113bfb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_(text_data):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(text_data)\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_input = tokenizer_(X_train)\n",
    "vocab_size_input = len(tokenizer_input.word_index) + 1\n",
    "tokenizer_target = tokenizer_(y_train)\n",
    "vocab_size_target = len(tokenizer_target.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9c2df04-8720-4c4f-b2d9-8900f4bd7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{dir}-{epochs}-tokenizer_input.pkl','wb') as f:\n",
    "    pkl.dump(tokenizer_input, f)\n",
    "\n",
    "with open(f'{dir}-{epochs}-tokenizer_target.pkl','wb') as f:\n",
    "    pkl.dump(tokenizer_target, f)\n",
    "    \n",
    "pkl.dump(tokenizer_input, open(f'{dir}-{epochs}-tokenizer_input.pkl', 'wb'))\n",
    "pkl.dump(tokenizer_target, open(f'{dir}-{epochs}-tokenizer_target.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "403c63c9-7a66-403b-a79f-9e06fcee84e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879, 891)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_input, vocab_size_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81ad8a6a-e1dc-48de-b446-c2d7ff443ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_batch(X= X_train,Y=y_train, batch_size=128):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_data_input = np.zeros((batch_size,max_lenght_source),dtype='float32') #metrix of batch_size*max_length_english\n",
    "            decoder_data_input = np.zeros((batch_size,max_lenght_target),dtype='float32') #metrix of batch_size*max_length_marathi\n",
    "            decoder_target_input = np.zeros((batch_size,max_lenght_target,vocab_size_target),dtype='float32') # 3d array one hot encoder decoder target data\n",
    "            for i, (input_text,target_text) in enumerate(zip(X[j:j+batch_size],Y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_data_input[i,t] = tokenizer_input.word_index[word] # Here we are storing the encoder \n",
    "                                                                         #seq in row here padding is done automaticaly as \n",
    "                                                                         #we have defined col as max_lenght\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    # if word == 'START_':\n",
    "                    #   word = 'start'\n",
    "                    # elif word == 'END_':\n",
    "                    #   word = 'end'\n",
    "                    decoder_data_input[i,t] = tokenizer_target.word_index[word] # same for the decoder sequence\n",
    "                    if t>0:\n",
    "                        decoder_target_input[i,t-1,tokenizer_target.word_index[word]] = 1 #target is one timestep ahead of decoder input because it does not have 'start tag'\n",
    "            # print(encoder_data_input.shape())\n",
    "            yield ([encoder_data_input,decoder_data_input],decoder_target_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cecaf5a-26f8-4b12-a372-d88732504b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None,),name=\"encoder_inputs\")\n",
    "emb_layer_encoder = Embedding(vocab_size_input, HIDDEN_DIM, mask_zero=True)(encoder_inputs)\n",
    "encoder = GRU(HIDDEN_DIM, return_state=True)\n",
    "encoder_outputs, state_h = encoder(emb_layer_encoder)\n",
    "# encoder_outputs, state_h, state_c = encoder(emb_layer_encoder)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,),name=\"decoder_inputs\")\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "emb_layer_decoder = Embedding(vocab_size_target,HIDDEN_DIM, mask_zero=True)(decoder_inputs)\n",
    "decoder_gru = GRU(HIDDEN_DIM, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _ = decoder_gru(emb_layer_decoder, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size_target, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63153d0e-941a-4bf0-87eb-ae29652c09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ebbda12-686d-47de-af07-63661bd10b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file=f'{dir}-{epochs}-train_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d12c688a-25f0-426a-b9dd-873ee155dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec1d51b8-bb57-4260-a64f-1e08364e1a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ONIGAT~1\\AppData\\Local\\Temp/ipykernel_3972/1782680856.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = generator_batch(X_train, y_train, batch_size = batch_size), steps_per_epoch = train_samples//batch_size, epochs=epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 7s 17ms/step - loss: 1.3454 - accuracy: 0.1521\n",
      "Epoch 2/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.2219 - accuracy: 0.1555\n",
      "Epoch 3/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.2076 - accuracy: 0.1553\n",
      "Epoch 4/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1831 - accuracy: 0.1557\n",
      "Epoch 5/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.1549 - accuracy: 0.1583\n",
      "Epoch 6/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.1330 - accuracy: 0.1620\n",
      "Epoch 7/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.1133 - accuracy: 0.1632\n",
      "Epoch 8/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 1.0956 - accuracy: 0.1634\n",
      "Epoch 9/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0702 - accuracy: 0.1657\n",
      "Epoch 10/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0654 - accuracy: 0.1647\n",
      "Epoch 11/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0428 - accuracy: 0.1674\n",
      "Epoch 12/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0430 - accuracy: 0.1695\n",
      "Epoch 13/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0331 - accuracy: 0.1691\n",
      "Epoch 14/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0208 - accuracy: 0.1710\n",
      "Epoch 15/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 1.0100 - accuracy: 0.1734\n",
      "Epoch 16/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9938 - accuracy: 0.1723\n",
      "Epoch 17/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9955 - accuracy: 0.1745\n",
      "Epoch 18/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9896 - accuracy: 0.1752\n",
      "Epoch 19/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9782 - accuracy: 0.1797\n",
      "Epoch 20/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9769 - accuracy: 0.1777\n",
      "Epoch 21/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9694 - accuracy: 0.1814\n",
      "Epoch 22/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9579 - accuracy: 0.1865\n",
      "Epoch 23/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9567 - accuracy: 0.1866\n",
      "Epoch 24/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9528 - accuracy: 0.1888\n",
      "Epoch 25/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9435 - accuracy: 0.1923\n",
      "Epoch 26/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9400 - accuracy: 0.1911\n",
      "Epoch 27/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9293 - accuracy: 0.1943\n",
      "Epoch 28/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9233 - accuracy: 0.1961\n",
      "Epoch 29/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9122 - accuracy: 0.1968\n",
      "Epoch 30/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.9115 - accuracy: 0.2016\n",
      "Epoch 31/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.9070 - accuracy: 0.1985\n",
      "Epoch 32/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.9010 - accuracy: 0.2030\n",
      "Epoch 33/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.8914 - accuracy: 0.2058\n",
      "Epoch 34/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8863 - accuracy: 0.2095\n",
      "Epoch 35/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8810 - accuracy: 0.2091\n",
      "Epoch 36/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8723 - accuracy: 0.2126\n",
      "Epoch 37/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8709 - accuracy: 0.2135\n",
      "Epoch 38/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.8626 - accuracy: 0.2149\n",
      "Epoch 39/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.8575 - accuracy: 0.2202\n",
      "Epoch 40/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8461 - accuracy: 0.2226\n",
      "Epoch 41/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8467 - accuracy: 0.2245\n",
      "Epoch 42/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.8323 - accuracy: 0.2276\n",
      "Epoch 43/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.8337 - accuracy: 0.2316\n",
      "Epoch 44/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.8225 - accuracy: 0.2333\n",
      "Epoch 45/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8271 - accuracy: 0.2376\n",
      "Epoch 46/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8190 - accuracy: 0.2403\n",
      "Epoch 47/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.8108 - accuracy: 0.2419\n",
      "Epoch 48/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.8076 - accuracy: 0.2470\n",
      "Epoch 49/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7964 - accuracy: 0.2498\n",
      "Epoch 50/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7952 - accuracy: 0.2562\n",
      "Epoch 51/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7904 - accuracy: 0.2561\n",
      "Epoch 52/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7862 - accuracy: 0.2645\n",
      "Epoch 53/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7800 - accuracy: 0.2605\n",
      "Epoch 54/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7755 - accuracy: 0.2659\n",
      "Epoch 55/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7693 - accuracy: 0.2699\n",
      "Epoch 56/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7649 - accuracy: 0.2708\n",
      "Epoch 57/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7546 - accuracy: 0.2723\n",
      "Epoch 58/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.7531 - accuracy: 0.2823\n",
      "Epoch 59/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7500 - accuracy: 0.2805\n",
      "Epoch 60/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7445 - accuracy: 0.2852\n",
      "Epoch 61/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7257 - accuracy: 0.2899\n",
      "Epoch 62/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7339 - accuracy: 0.2944\n",
      "Epoch 63/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7269 - accuracy: 0.2942\n",
      "Epoch 64/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7198 - accuracy: 0.3035\n",
      "Epoch 65/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.7176 - accuracy: 0.3022\n",
      "Epoch 66/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.7157 - accuracy: 0.3077\n",
      "Epoch 67/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.7066 - accuracy: 0.3127\n",
      "Epoch 68/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.7019 - accuracy: 0.3158\n",
      "Epoch 69/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6945 - accuracy: 0.3165\n",
      "Epoch 70/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6912 - accuracy: 0.3197\n",
      "Epoch 71/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6862 - accuracy: 0.3286\n",
      "Epoch 72/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6854 - accuracy: 0.3298\n",
      "Epoch 73/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6761 - accuracy: 0.3308\n",
      "Epoch 74/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6721 - accuracy: 0.3423\n",
      "Epoch 75/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6656 - accuracy: 0.3401\n",
      "Epoch 76/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6583 - accuracy: 0.3432\n",
      "Epoch 77/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6559 - accuracy: 0.3542\n",
      "Epoch 78/160\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.6505 - accuracy: 0.3588\n",
      "Epoch 79/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.6490 - accuracy: 0.3660\n",
      "Epoch 80/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6371 - accuracy: 0.3676\n",
      "Epoch 81/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6395 - accuracy: 0.3711\n",
      "Epoch 82/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6279 - accuracy: 0.3721\n",
      "Epoch 83/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6303 - accuracy: 0.3761\n",
      "Epoch 84/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6253 - accuracy: 0.3820\n",
      "Epoch 85/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6171 - accuracy: 0.3845\n",
      "Epoch 86/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6131 - accuracy: 0.3898\n",
      "Epoch 87/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6024 - accuracy: 0.3979\n",
      "Epoch 88/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6039 - accuracy: 0.3956\n",
      "Epoch 89/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5993 - accuracy: 0.4010\n",
      "Epoch 90/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5924 - accuracy: 0.4049\n",
      "Epoch 91/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5905 - accuracy: 0.4106\n",
      "Epoch 92/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5881 - accuracy: 0.4121\n",
      "Epoch 93/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5768 - accuracy: 0.4223\n",
      "Epoch 94/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5770 - accuracy: 0.4253\n",
      "Epoch 95/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5738 - accuracy: 0.4267\n",
      "Epoch 96/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.5679 - accuracy: 0.4264\n",
      "Epoch 97/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.5643 - accuracy: 0.4383\n",
      "Epoch 98/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.5574 - accuracy: 0.4413\n",
      "Epoch 99/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.5545 - accuracy: 0.4437\n",
      "Epoch 100/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5466 - accuracy: 0.4497\n",
      "Epoch 101/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5445 - accuracy: 0.4542\n",
      "Epoch 102/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5423 - accuracy: 0.4559\n",
      "Epoch 103/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5372 - accuracy: 0.4617\n",
      "Epoch 104/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5315 - accuracy: 0.4620\n",
      "Epoch 105/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5277 - accuracy: 0.4663\n",
      "Epoch 106/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5246 - accuracy: 0.4707\n",
      "Epoch 107/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5194 - accuracy: 0.4733\n",
      "Epoch 108/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5157 - accuracy: 0.4807\n",
      "Epoch 109/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5116 - accuracy: 0.4831\n",
      "Epoch 110/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5072 - accuracy: 0.4866\n",
      "Epoch 111/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.5005 - accuracy: 0.4903\n",
      "Epoch 112/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5003 - accuracy: 0.4981\n",
      "Epoch 113/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4908 - accuracy: 0.4934\n",
      "Epoch 114/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4913 - accuracy: 0.5045\n",
      "Epoch 115/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4831 - accuracy: 0.5067\n",
      "Epoch 116/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4860 - accuracy: 0.5082\n",
      "Epoch 117/160\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4790 - accuracy: 0.5104\n",
      "Epoch 118/160\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4739 - accuracy: 0.5099\n",
      "Epoch 119/160\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4731 - accuracy: 0.5208\n",
      "Epoch 120/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4642 - accuracy: 0.5191\n",
      "Epoch 121/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4642 - accuracy: 0.5274\n",
      "Epoch 122/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4594 - accuracy: 0.5300\n",
      "Epoch 123/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4571 - accuracy: 0.5360\n",
      "Epoch 124/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4516 - accuracy: 0.5385\n",
      "Epoch 125/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4485 - accuracy: 0.5426\n",
      "Epoch 126/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4445 - accuracy: 0.5443\n",
      "Epoch 127/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4394 - accuracy: 0.5484\n",
      "Epoch 128/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4363 - accuracy: 0.5540\n",
      "Epoch 129/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4324 - accuracy: 0.5568\n",
      "Epoch 130/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4284 - accuracy: 0.5592\n",
      "Epoch 131/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4285 - accuracy: 0.5630\n",
      "Epoch 132/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4164 - accuracy: 0.5601\n",
      "Epoch 133/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4194 - accuracy: 0.5680\n",
      "Epoch 134/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4165 - accuracy: 0.5720\n",
      "Epoch 135/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4108 - accuracy: 0.5779\n",
      "Epoch 136/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4086 - accuracy: 0.5782\n",
      "Epoch 137/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4065 - accuracy: 0.5815\n",
      "Epoch 138/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4017 - accuracy: 0.5881\n",
      "Epoch 139/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3977 - accuracy: 0.5903\n",
      "Epoch 140/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3939 - accuracy: 0.5923\n",
      "Epoch 141/160\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3922 - accuracy: 0.5979\n",
      "Epoch 142/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3881 - accuracy: 0.6016\n",
      "Epoch 143/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3884 - accuracy: 0.6025\n",
      "Epoch 144/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3819 - accuracy: 0.6046\n",
      "Epoch 145/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3797 - accuracy: 0.6078\n",
      "Epoch 146/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3753 - accuracy: 0.6163\n",
      "Epoch 147/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3703 - accuracy: 0.6164\n",
      "Epoch 148/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3702 - accuracy: 0.6189\n",
      "Epoch 149/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3670 - accuracy: 0.6192\n",
      "Epoch 150/160\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3650 - accuracy: 0.6232\n",
      "Epoch 151/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3596 - accuracy: 0.6257\n",
      "Epoch 152/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3588 - accuracy: 0.6289\n",
      "Epoch 153/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3545 - accuracy: 0.6286\n",
      "Epoch 154/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3534 - accuracy: 0.6332\n",
      "Epoch 155/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3512 - accuracy: 0.6369\n",
      "Epoch 156/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3471 - accuracy: 0.6405\n",
      "Epoch 157/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3444 - accuracy: 0.6430\n",
      "Epoch 158/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3401 - accuracy: 0.6411\n",
      "Epoch 159/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3379 - accuracy: 0.6518\n",
      "Epoch 160/160\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3373 - accuracy: 0.6482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x292e8062550>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%capture\n",
    "model.fit_generator(generator = generator_batch(X_train, y_train, batch_size = batch_size), steps_per_epoch = train_samples//batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7db8682d-539a-4ace-9c95-3f414ee4fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(f'{dir}-{epochs}-model.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(f'{dir}-{epochs}-model_weight.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e412cb7-8fb6-4910-85e2-8c4ea3f10c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(f'{dir}-{epochs}-model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_loaded = model_from_json(loaded_model_json)\n",
    "\n",
    "model_loaded.load_weights(f'{dir}-{epochs}-model_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8ac9691-08ef-462c-ba5a-255d2d9bb025",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs_inf = model_loaded.input[0]\n",
    "encoder_outputs_inf, inf_state_h = model_loaded.layers[4].output\n",
    "encoder_inf_states = [inf_state_h]\n",
    "encoder_model = Model(encoder_inputs_inf,encoder_inf_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb2d5383-b268-427f-abca-67bcdbd59614",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_h_input = Input(shape=(HIDDEN_DIM,))\n",
    "decoder_state_c_input = Input(shape=(HIDDEN_DIM,))\n",
    "decoder_state_input = [decoder_state_h_input]\n",
    "\n",
    "decoder_input_inf = model_loaded.input[1]\n",
    "decoder_emb_inf = model_loaded.layers[3](decoder_input_inf)\n",
    "decoder_gru_inf = model_loaded.layers[5]\n",
    "decoder_output_inf, decoder_state_h_inf = decoder_gru_inf(decoder_emb_inf, initial_state=decoder_state_input)\n",
    "decoder_state_inf = [decoder_state_h_inf]\n",
    "dense_inf = model_loaded.layers[6]\n",
    "decoder_output_final = dense_inf(decoder_output_inf)\n",
    "\n",
    "decoder_model = Model([decoder_input_inf] + decoder_state_input, [decoder_output_final] + decoder_state_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82b5c70c-a9ef-4da6-a1d5-fe34fe94238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{dir}-{epochs}-tokenizer_input.pkl','rb') as f:\n",
    "    tokenizer_input = pkl.load(f)\n",
    "with open(f'{dir}-{epochs}-tokenizer_target.pkl','rb') as f:\n",
    "    tokenizer_target = pkl.load(f)\n",
    "\n",
    "reverse_word_map_input = dict(map(reversed, tokenizer_input.word_index.items()))\n",
    "reverse_word_map_target = dict(map(reversed, tokenizer_target.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8714b9ba-6a9e-4b55-a8af-60f8ca3da9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(input_seq):\n",
    "    state_values_encoder = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tokenizer_target.word_index[start_target]\n",
    "    stop_condition = False\n",
    "    decoder_sentance = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        sample_word, decoder_h = decoder_model.predict([target_seq] + state_values_encoder)\n",
    "        sample_word_index = np.argmax(sample_word[0,-1,:])\n",
    "        decoder_word = reverse_word_map_target[sample_word_index]\n",
    "        decoder_sentance += ' '+ decoder_word\n",
    "        if (decoder_word == end_target or \n",
    "            len(decoder_sentance) > 70):\n",
    "            stop_condition = True\n",
    "        target_seq[0, 0] = sample_word_index\n",
    "        state_values_encoder = [decoder_h]\n",
    "        \n",
    "    return decoder_sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f03d272-1854-4bb8-8c55-d48a42a2e103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "она говорит порусски\n",
      "[[ 28  56 513   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_8\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 50) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ONIGAT~1\\AppData\\Local\\Temp/ipykernel_3972/1958753392.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpredicted_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test sentance: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentance: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ONIGAT~1\\AppData\\Local\\Temp/ipykernel_3972/313384065.py\u001b[0m in \u001b[0;36mdecode_seq\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0msample_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstate_values_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0msample_word_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mdecoder_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreverse_word_map_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_word_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programms\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programms\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"D:\\Programms\\Anaconda\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_8\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 50) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    sentance = X_test[i]\n",
    "    original_target = y_test[i]\n",
    "    input_seq = tokenizer_input.texts_to_sequences([sentance])\n",
    "    pad_sequence = pad_sequences(input_seq, maxlen= 30, padding='post')\n",
    "    print(sentance)\n",
    "    print(pad_sequence)\n",
    "    predicted_target = decode_seq(pad_sequence)\n",
    "    print(\"Test sentance: \",i+1)\n",
    "    print(\"sentance: \",sentance)\n",
    "    print(\"origianl translate:\",original_target[3:-3])\n",
    "    print(\"predicted Translate:\",predicted_target[:-3])\n",
    "    print(\"==\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286e0b3-0c4c-48d5-b817-40e1339df1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    sentance = X_train[i]\n",
    "    original_target = y_train[i]\n",
    "    input_seq = tokenizer_input.texts_to_sequences([sentance])\n",
    "    pad_sequence = pad_sequences(input_seq, maxlen= 30, padding='post')\n",
    "    predicted_target = decode_seq(pad_sequence)\n",
    "    print(\"Test sentance: \",i+1)\n",
    "    print(\"sentance: \",sentance)\n",
    "    print(\"origianl translate:\",original_target[3:-3])\n",
    "    print(\"predicted Translate:\",predicted_target[:-3])\n",
    "    print(\"==\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7dc63-781f-4ea5-b1b4-a702d7fe8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentance = str(input())\n",
    "input_seq = tokenizer_input.texts_to_sequences([sentance])\n",
    "pad_sequence = pad_sequences(input_seq, maxlen= 30, padding='post')\n",
    "predicted_target = decode_seq(pad_sequence)\n",
    "print(\"predicted Translate:\",predicted_target[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c15b6-9095-453e-abb7-465a7504273a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
