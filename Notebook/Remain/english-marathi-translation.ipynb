{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4l2aoR5DZnQm",
    "tags": []
   },
   "source": [
    "# Downloding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6465,
     "status": "ok",
     "timestamp": 1587947324829,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "0-2viFpNt1Vc",
    "outputId": "b66c2bf8-a597-4f01-d68e-a9073347f356"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" не является внутренней или внешней\n",
      "командой, исполняемой программой или пакетным файлом.\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: www.manythings.org\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: http://www.manythings.org/anki/\" --header=\"Cookie: __cfduid=d8e66d33dc7e0734531aca305586b998e1587483534; __utmc=3028652; __utma=3028652.1511764841.1587483538.1587483538.1587538758.2; __utmz=3028652.1587538758.2.2.utmcsr=towardsdatascience.com|utmccn=(referral)|utmcmd=referral|utmcct=/word-level-english-to-marathi-neural-machine-translation-using-seq2seq-encoder-decoder-lstm-model-1a913f2dc4a7; __utmb=3028652.1.10.1587538758\" --header=\"Connection: keep-alive\" \"http://www.manythings.org/anki/mar-eng.zip\" -c -O 'mar-eng.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1826,
     "status": "ok",
     "timestamp": 1587954214245,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "xXCBsotMuZky",
    "outputId": "06946c91-1e57-43dd-b752-d75e54b0cec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] Системе не удается найти указанный путь: 'drive/My\\\\ Drive/English-Marathi translation'\n",
      "C:\\Users\\Onigatari\\Desktop\\Graduate-Work\\Notebook\\Remain\n"
     ]
    }
   ],
   "source": [
    "cd drive/My\\ Drive/English-Marathi translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zy6w3gFXZxC_"
   },
   "source": [
    "# Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BmQjdQsukD_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"unzip\" не является внутренней или внешней\n",
      "командой, исполняемой программой или пакетным файлом.\n"
     ]
    }
   ],
   "source": [
    "!unzip mar-eng.zip -d ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1r3aDmeLZ78z"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "beMtEOA-lqwe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, Input, Dense,Embedding\n",
    "from keras.models import Model,load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import model_from_json\n",
    "import pickle as pkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3nahOTPaaBQO"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11954,
     "status": "ok",
     "timestamp": 1587947330442,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "fNhiQugGusId",
    "outputId": "783d577e-b42b-42e8-c73d-42b234b8fa00"
   },
   "outputs": [],
   "source": [
    "dir = 'eng-mar.txt'\n",
    "cur_path = os.path.abspath('')\n",
    "new_path = os.path.relpath(f'../Date/{dir}', cur_path)\n",
    "with open(new_path, encoding='utf-8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6vFoOxNaJUI"
   },
   "source": [
    "# Cleaning and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGynAoMfu2fv"
   },
   "outputs": [],
   "source": [
    "# we need to clean the data\n",
    "uncleaned_data_list = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11928,
     "status": "ok",
     "timestamp": 1587947330445,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "ZaN8nVoR2jW2",
    "outputId": "f4b9831b-fed0-42fb-b858-c954afd6fb56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncleaned_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1v7_pj82oc2"
   },
   "outputs": [],
   "source": [
    "uncleaned_data_list = uncleaned_data_list[:38695]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12255,
     "status": "ok",
     "timestamp": 1587947330815,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "1-XAEwG431Zf",
    "outputId": "9aebc3f4-d11a-4e24-ea12-9ad5ea859ff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38695"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncleaned_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "isQ1zg_dv-LH"
   },
   "outputs": [],
   "source": [
    "english_word = []\n",
    "marathi_word = []\n",
    "cleaned_data_list = []\n",
    "for word in uncleaned_data_list:\n",
    "    english_word.append(word.split('\\t')[:-1][0])\n",
    "    marathi_word.append(word.split('\\t')[:-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12224,
     "status": "ok",
     "timestamp": 1587947330818,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "uoYU7JY77meB",
    "outputId": "5cba5c9e-11ed-4981-919c-ecc285c9229d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38695, 38695)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_word), len(marathi_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUjyh3V7aY9b"
   },
   "source": [
    "# Creating the dataframe and saving the data into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMHxLefN5C6p"
   },
   "outputs": [],
   "source": [
    "language_data = pd.DataFrame(columns=['English','Marathi'])\n",
    "language_data['English'] = english_word\n",
    "language_data['Marathi'] = marathi_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-0s1dw_7cUj"
   },
   "outputs": [],
   "source": [
    "# saving to csv\n",
    "language_data.to_csv('language_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "APANdWiI7jQ_"
   },
   "outputs": [],
   "source": [
    "language_data = pd.read_csv('language_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2857,
     "status": "ok",
     "timestamp": 1587955633621,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "pKsFw0bA5Uhe",
    "outputId": "9e887515-e9ae-4c40-ac36-3b4e5047eb42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Marathi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>जा.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>पळ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>धाव!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>पळा!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>धावा!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English Marathi\n",
       "0     Go.     जा.\n",
       "1    Run!     पळ!\n",
       "2    Run!    धाव!\n",
       "3    Run!    पळा!\n",
       "4    Run!   धावा!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2254,
     "status": "ok",
     "timestamp": 1587955633622,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "btTBPBR6yvwz",
    "outputId": "b317fbb9-6006-4f4e-ab0a-b1dd6173d246"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Marathi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38690</th>\n",
       "      <td>If religion were synonymous with morality, Bra...</td>\n",
       "      <td>जर धर्म व नीतिमत्ता समानार्थी शब्द असते, तर ब्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38691</th>\n",
       "      <td>Just saying you don't like fish because of the...</td>\n",
       "      <td>हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38692</th>\n",
       "      <td>The Japanese Parliament today officially elect...</td>\n",
       "      <td>आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38693</th>\n",
       "      <td>Tom tried to sell his old VCR instead of throw...</td>\n",
       "      <td>टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38694</th>\n",
       "      <td>You can't view Flash content on an iPad. Howev...</td>\n",
       "      <td>आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 English  \\\n",
       "38690  If religion were synonymous with morality, Bra...   \n",
       "38691  Just saying you don't like fish because of the...   \n",
       "38692  The Japanese Parliament today officially elect...   \n",
       "38693  Tom tried to sell his old VCR instead of throw...   \n",
       "38694  You can't view Flash content on an iPad. Howev...   \n",
       "\n",
       "                                                 Marathi  \n",
       "38690  जर धर्म व नीतिमत्ता समानार्थी शब्द असते, तर ब्...  \n",
       "38691  हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...  \n",
       "38692  आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...  \n",
       "38693  टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...  \n",
       "38694  आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exuFz8nTarzz"
   },
   "source": [
    "## Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MQDC2gD7V5r"
   },
   "outputs": [],
   "source": [
    "english_text = language_data['English'].values\n",
    "marathi_text = language_data['Marathi'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2848,
     "status": "ok",
     "timestamp": 1587955635283,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "N_gZlBTV6r0k",
    "outputId": "cca80925-65f8-4f7b-a5cb-2b248618b62c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Go.', 'जा.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_text[0], marathi_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1989,
     "status": "ok",
     "timestamp": 1587955635285,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "xmZzm1OP70jC",
    "outputId": "b45a018c-4276-48d2-de0a-724a2dfa99a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38695, 38695)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_text), len(marathi_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfZYTe68717a"
   },
   "outputs": [],
   "source": [
    "english_text_ = [x.lower() for x in english_text]\n",
    "marathi_text_ = [x.lower() for x in marathi_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2654,
     "status": "ok",
     "timestamp": 1587955638769,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "pzM5Cw4z8yEC",
    "outputId": "1794139c-8223-4af8-a7f1-dd0300b0fdea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(english_text_), type(marathi_text_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhAomWqya6ry"
   },
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ahm-n5IN9MM4"
   },
   "outputs": [],
   "source": [
    "english_text_ = [re.sub(\"'\",'',x) for x in english_text_]\n",
    "marathi_text_ = [re.sub(\"'\",'',x) for x in marathi_text_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHJcMxc69ly7"
   },
   "outputs": [],
   "source": [
    "def remove_punc(text_list):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    removed_punc_text = []\n",
    "    for sent in text_list:\n",
    "        sentance = [w.translate(table) for w in sent.split(' ')]\n",
    "        removed_punc_text.append(' '.join(sentance))\n",
    "    return removed_punc_text\n",
    "english_text_ = remove_punc(english_text_)\n",
    "marathi_text_ = remove_punc(marathi_text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCB_msy4GpVt"
   },
   "outputs": [],
   "source": [
    "# removing the digits from english sentances\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "removed_digits_text = []\n",
    "for sent in english_text_:\n",
    "    sentance = [w.translate(remove_digits) for w in sent.split(' ')]\n",
    "    removed_digits_text.append(' '.join(sentance))\n",
    "english_text_ = removed_digits_text\n",
    "\n",
    "# removing the digits from the marathi sentances\n",
    "marathi_text_ = [re.sub(\"[२३०८१५७९४६]\",\"\",x) for x in marathi_text_]\n",
    "marathi_text_ = [re.sub(\"[\\u200d]\",\"\",x) for x in marathi_text_]\n",
    "\n",
    "# removing the stating and ending whitespaces\n",
    "english_text_ = [x.strip() for x in english_text_]\n",
    "marathi_text_ = [x.strip() for x in marathi_text_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jkuf2FGVJ8qE"
   },
   "outputs": [],
   "source": [
    "# removing the starting and ending whitespaces\n",
    "english_text_ = [x.strip() for x in english_text_]\n",
    "marathi_text_ = [x.strip() for x in marathi_text_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXLUAQtBMBDV"
   },
   "outputs": [],
   "source": [
    "# Putting the start and end words in the marathi sentances\n",
    "marathi_text_ = [\"start \" + x + \" end\" for x in marathi_text_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1600,
     "status": "ok",
     "timestamp": 1587955649759,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "zBDFphN7MhNa",
    "outputId": "d7f97b2c-c38c-4606-bb86-9810c5c68bd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start जा end', 'go')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manipulated_marathi_text_\n",
    "marathi_text_[0], english_text_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 941,
     "status": "ok",
     "timestamp": 1587955650539,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "MeMFP2XOIHo_",
    "outputId": "3fe41172-930e-4103-d535-a4308107bc57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38695, 38695)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(marathi_text_),len(english_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2u1xzDWnbAEP"
   },
   "source": [
    "# Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMOn0wFsL0Dx"
   },
   "outputs": [],
   "source": [
    "X = english_text_\n",
    "Y = marathi_text_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2689,
     "status": "ok",
     "timestamp": 1587955654319,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "rtn9Lcj8NOQ9",
    "outputId": "0ddffc2f-bd34-4270-c313-3e8ee8d4d442"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34825, 34825, 3870, 3870)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.1)\n",
    "len(X_train),len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3135,
     "status": "ok",
     "timestamp": 1587951153995,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "eOVqDO1h6bjA",
    "outputId": "4b43c9f5-2e88-461e-af5b-9759e31ec24f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('go', 'start जा end')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3113,
     "status": "ok",
     "timestamp": 1587951153997,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "0M5rQy8E8Per",
    "outputId": "706c3a64-8c2f-4f96-8b56-47492e3f78d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('thats enough i dont want any more', 'start तेवढं पुरे मला अजून नको end')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXR7eYWbbNEy"
   },
   "source": [
    "## Data preparing for encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Djnk8zztnDIK"
   },
   "outputs": [],
   "source": [
    "# preparing data for the word embedding\n",
    "def Max_length(data):\n",
    "    max_length_ = max([len(x.split(' ')) for x in data])\n",
    "    return max_length_\n",
    "\n",
    "#Training data\n",
    "max_length_english = Max_length(X_train)\n",
    "max_lenght_marathi = Max_length(y_train)\n",
    "\n",
    "#Test data\n",
    "max_length_english_test = Max_length(X_test)\n",
    "max_lenght_marathi_test = Max_length(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3086,
     "status": "ok",
     "timestamp": 1587951154011,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "ROno0D42S5Eg",
    "outputId": "5c906c2c-02b2-44e0-ba24-0f88782f2a39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_lenght_marathi, max_length_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZopVpijTusFF"
   },
   "outputs": [],
   "source": [
    "\n",
    "def tokenizer_(text_data):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(text_data)\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_input = tokenizer_(X_train)\n",
    "vocab_size_input = len(tokenizer_input.word_index) + 1\n",
    "tokenizer_target = tokenizer_(y_train)\n",
    "vocab_size_target = len(tokenizer_target.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-A-4zuYHJ492"
   },
   "outputs": [],
   "source": [
    "with open('tokenizer_input.pkl','wb') as f:\n",
    "    pkl.dump(tokenizer_input,f)\n",
    "\n",
    "with open('tokenizer_target.pkl','wb') as f:\n",
    "    pkl.dump(tokenizer_target,f)\n",
    "pkl.dump(tokenizer_input, open('tokenizer_input.pkl', 'rb'))\n",
    "pkl.dump(tokenizer_target, open('tokenizer_target.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4310,
     "status": "ok",
     "timestamp": 1587951155289,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "ozVJY1_7xcpS",
    "outputId": "a0c78f00-3269-41d6-a12d-9b1d83a2117a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5397, 12762)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_input,vocab_size_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSSC7PqL3ZZO"
   },
   "outputs": [],
   "source": [
    "# encoder_data_input = []\n",
    "# decoder_data_input = []\n",
    "# decoder_target_input = []\n",
    "# for i,(input_text,target_text) in enumerate(zip(X_train,y_train)):\n",
    "#   # Encoder input sequence\n",
    "#   # print(input_text)\n",
    "#   sequence_input = tokenizer_input.texts_to_sequences([input_text])\n",
    "#   # print(sequence_input)\n",
    "#   pad_seq_encoder =  pad_sequences(sequence_input, maxlen=max_length_english, padding='post')\n",
    "#   # print(pad_seq_encoder.shape)\n",
    "#   encoder_data_input.extend(pad_seq_encoder)# Always extend else it will make it 3 dimensional data\n",
    "\n",
    "#   #Decoder input sequence\n",
    "#   # print(target_text)\n",
    "#   sequence_target = tokenizer_target.texts_to_sequences([target_text])\n",
    "#   # print(sequence_target)\n",
    "#   pad_seq_decoder =  pad_sequences(sequence_target, maxlen=max_lenght_marathi, padding='post')\n",
    "#   decoder_data_input.extend(pad_seq_decoder)# Always extend else it will make it 3 dimensional data\n",
    "\n",
    "#   #Decoder target sequence\n",
    "#   # print(\"orignal target word:\",target_text)\n",
    "#   word = target_text.split(' ')\n",
    "#   word.pop(0)\n",
    "#   # print(word)\n",
    "#   decoder_target_word = ' '.join(word)\n",
    "#   # print(\"after pop target word: \", decoder_target_word)\n",
    "#   # print(decoder_target_word)\n",
    "#   decoder_target_word_one_hot = one_hot(decoder_target_word,vocab_size_target)\n",
    "#   # sequence_target_decoder = tokenizer_target.texts_to_sequences([decoder_target_word])\n",
    "#   # print(sequence_target_decoder)\n",
    "#   # pad_seq_decoder_target =  pad_sequences(sequence_target_decoder, maxlen=max_lenght_marathi, padding='post')\n",
    "#   decoder_target_input.append(np.array(decoder_target_word_one_hot))\n",
    "#   # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujwuh9kq2tnE"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_1744/869966309.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ONIGAT~1\\AppData\\Local\\Temp/ipykernel_1744/869966309.py\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    if t>0:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def generator_batch(X = X_train,Y = y_train, batch_size = 128):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_data_input = np.zeros((batch_size,max_length_english),dtype='float32') #metrix of batch_size*max_length_english\n",
    "            decoder_data_input = np.zeros((batch_size,max_lenght_marathi),dtype='float32') #metrix of batch_size*max_length_marathi\n",
    "            decoder_target_input = np.zeros((batch_size,max_lenght_marathi,vocab_size_target),dtype='float32') # 3d array one hot encoder decoder target data\n",
    "            for i, (input_text,target_text) in enumerate(zip(X[j:j+batch_size],Y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_data_input[i,t] = tokenizer_input.word_index[word] # Here we are storing the encoder \n",
    "                                                                     #seq in row here padding is done automaticaly as \n",
    "                                                                     #we have defined col as max_lenght\n",
    "        for t, word in enumerate(target_text.split()):\n",
    "          # if word == 'START_':\n",
    "          #   word = 'start'\n",
    "          # elif word == 'END_':\n",
    "          #   word = 'end'\n",
    "            decoder_data_input[i,t] = tokenizer_target.word_index[word] # same for the decoder sequence\n",
    "            if t > 0:\n",
    "                decoder_target_input[i,t-1,tokenizer_target.word_index[word]] = 1 #target is one timestep ahead of decoder input because it does not have 'start tag'\n",
    "      # print(encoder_data_input.shape())\n",
    "        yield ([encoder_data_input,decoder_data_input],decoder_target_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2ETtDfbAfeW"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8VzF3MKAeRM"
   },
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None,),name=\"encoder_inputs\")\n",
    "emb_layer_encoder = Embedding(vocab_size_input,latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(emb_layer_encoder)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,),name=\"decoder_inputs\")\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "emb_layer_decoder = Embedding(vocab_size_target,latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(emb_layer_decoder, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size_target, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3x4d-DhIJB8"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12928,
     "status": "ok",
     "timestamp": 1587951164008,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "wpvNNuDPI1iF",
    "outputId": "2f05e87c-56e4-4af4-fd3e-2354d46f0e79"
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='train_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FAAhjyye03j"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 776599,
     "status": "ok",
     "timestamp": 1587953750533,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "vRm3DCeceq74",
    "outputId": "a38d3107-27b7-4b31-9ef0-63b0a2a05c86"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator = generator_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8K0ek58scT0O"
   },
   "source": [
    "## Saving the model into Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGEbCFAacJin"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_weight_5.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpZVI5fscZlI"
   },
   "source": [
    "## Loading the model and weight from Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33D-5jOOWACX"
   },
   "outputs": [],
   "source": [
    "\n",
    "# loading the model architecture and asigning the weights\n",
    "json_file = open('model_2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_loaded = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_loaded.load_weights(\"model_weight_5.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTGbqN5vlf5Y"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BR9H5oj4-CFg"
   },
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "#inference encoder\n",
    "encoder_inputs_inf = model_loaded.input[0] #Trained encoder input layer\n",
    "encoder_outputs_inf, inf_state_h, inf_state_c = model_loaded.layers[4].output # retoring the encoder lstm output and states\n",
    "encoder_inf_states = [inf_state_h,inf_state_c]\n",
    "encoder_model = Model(encoder_inputs_inf,encoder_inf_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjjeeATugI9c"
   },
   "outputs": [],
   "source": [
    "#inference decoder\n",
    "# The following tensor will store the state of the previous timestep in the \"starting the encoder final time step\"\n",
    "decoder_state_h_input = Input(shape=(latent_dim,)) #becase during training we have set the lstm unit to be of 50\n",
    "decoder_state_c_input = Input(shape=(latent_dim,))\n",
    "decoder_state_input = [decoder_state_h_input,decoder_state_c_input]\n",
    "\n",
    "# # inference decoder input\n",
    "decoder_input_inf = model_loaded.input[1] #Trained decoder input layer\n",
    "# decoder_input_inf._name='decoder_input'\n",
    "decoder_emb_inf = model_loaded.layers[3](decoder_input_inf)\n",
    "decoder_lstm_inf = model_loaded.layers[5]\n",
    "decoder_output_inf, decoder_state_h_inf, decoder_state_c_inf = decoder_lstm_inf(decoder_emb_inf, initial_state =decoder_state_input)\n",
    "decoder_state_inf = [decoder_state_h_inf,decoder_state_c_inf]\n",
    "#inference dense layer\n",
    "dense_inf = model_loaded.layers[6]\n",
    "decoder_output_final = dense_inf(decoder_output_inf)# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "decoder_model = Model([decoder_input_inf]+decoder_state_input,[decoder_output_final]+decoder_state_inf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkjeICV2cjXD"
   },
   "source": [
    "## loading the saved tokenizer for the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yvm5xSHaIl1l"
   },
   "outputs": [],
   "source": [
    "with open('tokenizer_input.pkl','rb') as f:\n",
    "    tokenizer_input = pkl.load(f)\n",
    "with open('tokenizer_target.pkl','rb') as f:\n",
    "    tokenizer_target = pkl.load(f)\n",
    "# Creating the reverse mapping to get the word from the index in the sequence\n",
    "reverse_word_map_input = dict(map(reversed, tokenizer_input.word_index.items()))\n",
    "reverse_word_map_target = dict(map(reversed, tokenizer_target.word_index.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-G00SACUc0tE"
   },
   "source": [
    "## Code for generating the translated sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3gMi0toQGWn"
   },
   "outputs": [],
   "source": [
    "# Code to predct the input sentences translation\n",
    "def decode_seq(input_seq):\n",
    "  # print(\"input_seq=>\",input_seq)\n",
    "    state_values_encoder = encoder_model.predict(input_seq)\n",
    "  # intialize the target seq with start tag\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tokenizer_target.word_index['start']\n",
    "  # print(\"target_seq:=>\",target_seq)\n",
    "    stop_condition = False\n",
    "    decoder_sentance = ''\n",
    "  # print(\"Beforee the while loop\")\n",
    "    while not stop_condition:\n",
    "        sample_word , decoder_h,decoder_c= decoder_model.predict([target_seq] + state_values_encoder)\n",
    "    # print(\"sample_word: =>\",sample_word)\n",
    "        sample_word_index = np.argmax(sample_word[0,-1,:])\n",
    "    # print(\"sample_word_index: \",sample_word_index)\n",
    "        decoder_word = reverse_word_map_target[sample_word_index]\n",
    "        decoder_sentance += ' '+ decoder_word\n",
    "    # print(\"decoded word:=>\",decoder_word)\n",
    "    # print(len(decoder_sentance))\n",
    "    # print(\"len(decoder_sentance) > 70: \",len(decoder_sentance) > 70)\n",
    "    # print('decoder_word == \"end\"',decoder_word == 'end')\n",
    "    # print(decoder_word == 'end' or len(decoder_sentance) > 70)\n",
    "    # stop condition for the while loop\n",
    "        if (decoder_word == 'end' or \n",
    "            len(decoder_sentance) > 70):\n",
    "            stop_condition = True\n",
    "            # print(\"from if condition\")\n",
    "        # target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sample_word_index\n",
    "        # print(target_seq)\n",
    "        state_values_encoder = [decoder_h,decoder_c]\n",
    "    return decoder_sentance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gN4tgQl-dHKy"
   },
   "source": [
    "## some sentance translation from english sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3327,
     "status": "ok",
     "timestamp": 1587955667198,
     "user": {
      "displayName": "bablu singh",
      "photoUrl": "",
      "userId": "03001583391770728404"
     },
     "user_tz": -330
    },
    "id": "ihME9UbyWQmS",
    "outputId": "8fe31c13-a86c-46c4-d6f9-685443cd6a67"
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    sentance = X_test[i]\n",
    "    original_target = y_test[i]\n",
    "    input_seq = tokenizer_input.texts_to_sequences([sentance])\n",
    "    pad_sequence = pad_sequences(input_seq, maxlen= 30, padding='post')\n",
    "    # print('input_sequence =>',input_seq)\n",
    "    # print(\"pad_seq=>\",pad_sequence)\n",
    "    predicted_target = decode_seq(pad_sequence)\n",
    "    print(\"Test sentance: \",i+1)\n",
    "    print(\"sentance: \",sentance)\n",
    "    print(\"origianl translate:\",original_target[6:-4])\n",
    "    print(\"predicted Translate:\",predicted_target[:-4])\n",
    "    print(\"==\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1bkBFHmbYwK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPSXwH/gQgxPd4dz1iQZvKT",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1LCNMVbY7XCqDmrau3uaaecNjWItTX-XC",
   "name": "english-marathi-translation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
